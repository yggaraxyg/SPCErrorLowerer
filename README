SPC Error Lowerer: a series of programs for creating graphs based on simulations of SPC cameras.


-------------------------------------------------------------------------------------------------
Citation:

This is a repo derived from the work of:

Sadekar, K., Maier, D., & Ingle, A. (2025). Single-Photon 3D Imaging with Equi-Depth Photon Histograms. 
In European Conference on Computer Vision (pp. 381-398). Springer, Cham.

-------------------------------------------------------------------------------------------------
Description:

this repo SPCErrorLowerer, contrary to it's name, does not truly lower error in SPCs.
instead, it measures the error of SPCs under different circumstances and settings.
The intention of this measurement is to create graphs and diagrams displaying the optimal attenuation for several distances, and how Freerunmode differs from standard SPC modes, potentially improving the accuracy of SPC images following the analysis of said graphs.

-------------------------------------------------------------------------------------------------
Needed and Reccomended Libraries:

in order to use this repo, one will need several libraries including but not limited to:

-numpy
-torch
-matplotlib
-tqdm
-opencv
-miniconda

-------------------------------------------------------------------------------------------------
Use: Pt 1

in order to use this repo, one must follow several steps:

Firstly, one must move to the file SPCSimLib, and execute the following command.

pip install .

this installs the SPCSimLib library, allowing the file to complete.

Due to certain errors, the SPCSimLib folder may be empty.
If the SPCSimLib folder is empty, please go to https://github.com/kaustubh-sadekar/SPCSimLib and import the library from there.

-------------------------------------------------------------------------------------------------
Use: Pt 2

Secondly, one must use the following command.

python3 ParameterizedTimeEDH.py [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15]

this command creates a set of graphs, though none are the ones we require. the vast majority of them are created to show data on individual runs. they are stored in the TimePhotos file. data of our greater runs and every multiple run is stored in the RunData file. this data, once graphed with graphit.py, will produce the graphs I need to complete this project.

Please note that repeatedly running this command WILL create many, many graphs in the TimePhotos file. (Tens of Gigabytes worth.) if you do not wish to create graphs, you may remove the hashtag before the three apostrophes on line 121,
this will disable saving graphs.

each of these parameters modifies the settings of the camera and the data in the graph produced. an explanation of each variable is below:

[1] - this parameter represents the 'signal' value of the simulation (meaning the intensity of laser in the SPC)
[2] - this parameter represents the 'background' value of the simulation (meaning the intensity of backround illumination in the scene)
[3] - this parameter represents the begining value in the attenuation multiplier (Meaning when the command is run, the attenuation multiplier will begin at this value)
[4] - this parameter represents the ending value in the attenuation multiplier (Meaning when the command is run, the attenuation multiplier will end at this value)
[5] - this parameter represents the interval of the attenuation multiplier (Meaning when the command is run, the attenuation multiplier will increment up by this value)
[6] - this parameter represents the max time of a single cycle (Meaning the SPC camera will reset every [this value]th time bin)
[7] - this parameter represents the number of overall cycles the camera will be active (Meaning when the command is run, the simulation will run for that many time bins)
[8] - this parameter represents the FWHM (Meaning the length of the laser pulse.)
[9] - this parameter represents the number of repetitions for each attenuation value (Meaning when the command is run, every attenuation value will run this many sims, and take the average of the data.)
[10] - this parameter represents the distance from the camera of our pictured object in terms of TMAX.
[11] - this parameter represents the number of time bins in our Equal-depth histogram (meaning when the command is run, the number of chunks we cut the data into is this value.)
[12] - this parameter represents the number of pulses (meaning when the command is run, the amount of data we collect will be equal to this value)
[13] - this parameter represents the deadtime of the SPC (meaning when the command is run, the SPC will be busy for this amount of nanoseconds after each intaken photon)
(please note the following parameters are booleans, emabled at values (1|inf) and disabled at values (-inf|0))
[14] - this parameter represents whether or not the simulation will be run in freesrun (asyncronous) mode (enabled) or paralell mode (disabled)
[15] - this parameter represents whether or not the simulation will run multiple times (yes, this's disablment makes parameters [3-5] and [9] irrelevant.). please note when this is disabled, it will not produce graphable data, merely a smaller data-simulation graph.

-------------------------------------------------------------------------------------------------
Use: Pt 3

After this is done, one can then take the resultant .npz file and graph it's contents with graphit.py

graphit.py is used in the following manner:

graphit.py [1] [2] [3] [4] [5] [6] [7] [8]...[inf]

[1] - this parameter represents whether or not the error data graphed will use the error of the Equi-Width Hisogram or the Equi-Depth Histogram. (-inf-0: Depth, 1-inf: width)
[2] - this parameter represents whether or not the Y axis of the graphs will be shared. (-inf-0: local Y, 1-inf: shared Y)
[3] - this parameter represents the sig of the input dataset (Note this need not match the data, it is for labeling purposes only)
[4] - this parameter represents the bkg of the input dataset (Note this need not match the data, it is for labeling purposes only)
[5] - this parameter represents the true distance from the camera of the input dataset (Note this need not match the data, it is for labeling purposes only)
[6] - this parameter represents the FWHM of the input dataset (Note this need not match the data, it is for labeling purposes only)
[7] - this is the name of the file you want to graph.
[8...inf] (optional) - these are the names of more files that you want to graph. graphs will be shown in a row.  please note that if you try to graph exactly 6 files the program will assume you are trying to make a graph showing the difference between freeRunMode and non-freeRunMode for deadtimes 0, 15, and 75. while there is no parameter to disable this, you can uncomment line 32 to disable this.

the graph will be saved to the Graphs file.
-------------------------------------------------------------------------------------------------
Use: Pt 4

after preparing runData and graphing said data, it might occur to one to run statistical analysis on said data. as such, I have prepared two programs for analytical use. the first program is repackager.py. repackager.py takes in multiple .npz files, retrieves errorWidth and errorDepth (the error values for the width and depth calculations of histograms), then puts them together in one alrge .npz file. while it is indended to take in both errorWidth and erorrDepth, commenting and uncommenting certain clearly-marked lines in the code allows one to repackage just one of the two if one wishes.

repackager.py is used in the following manner:

repackager.py  [1] [2] [3]...[inf]

[1] - this parameter repsetents whether or not a file will be compiled as a keeping all data and not taking the average (1) or keeping the number of values and averaging all inputs (0)
[2] - this parameter represents the name of the file all input files are to be repackaged into. the file should end with .npz, and it need not exist before running this command
[3] - this parameter represents the name of the first file which will be repackaged.
[4...inf] (optional) - this parameter represents the name of the other files to be repackaged.

If one is choosing to run a paired t-test, one must be certain to put in filenames in the EXACTLY the same order both times. the repackager WON'T sort them for you.

-------------------------------------------------------------------------------------------------
Use: Pt 5

once data has been repackaged, all one needs to do to run a statistical test is use the statrun.py program. statrun.py is a program that either runs a paired t-test or a two-sample t-test on two .npz files. 

statrun.py  is used in the following manner:

statrun.py [1] [2] [3] [4] [5]

[1] - this parameter represents wheter the test will be a two sample t-test (0 and less) or a paired t-test. (1 and more)
[2] - this parameter represents	if the alternate hypothesis is that M1 < M2 (-1 and less), M1 != M2 (0), or M1 > M2 (1 and more).
[3] - this parameter represents the alpha of all tests.
[4] - this parameter is the name of dataset 1
[5] - this parameter is the name of dataset 2

-------------------------------------------------------------------------------------------------
Example 1:

This example is meant to display the graphing functions of this program.

first, we simulate our data with the following line of code:

=
python3 ParameterizedTimeEDH.py 1 3 0 1 0.05 100 1000 1.5 10 0.5 16 10000 50 1 1
=

this will create a multi-run datafile in freerun mode with laser illumination 1 and backround 3. the attenuation will run from 0 to 100%, changing by 5% each repetition-cycle.
the repetition-cycles will be 10 repeitions long, and will average out the values. the SPC will NOT reset every 100 cycles. (this is because freerun mode is on.)
the whole thing will run for 1000 tbins, and it will intake 10000 pulses. after every pulse, the SPC will deactivate for 50 ns to simulate the delay from data being recorded.
the laser will fire for 1.5 ns, and the target is 0.4 of the way through 100 cycles. the resultant histogram will have 16 bins.

the error will be saved in the following file:

RunData/free-True-sig-1.0000-bkg-3.0000-tmax-100.0-tbins-1000-FWHM-1.5-reps-10-cent-0.50-bins-16-pulses-10000-deadtime-50.npz

and to graph it one would might use the following command:

=
python3 graphit.py 0 1 1 3 0.5 1.5 RunData/free-True-sig-1.0000-bkg-3.0000-tmax-100.0-tbins-1000-FWHM-1.5-reps-10-cent-0.50-bins-16-pulses-10000-deadtime-50.npz
=

which would then save the graph under the name

Graphs/sig-1-bkg-3FWHM-1.5-dist-0.5-Sharedy-Depth.png

-------------------------------------------------------------------------------------------------
Example 2: 

this exampel is emnet to display the statistical analysis functions of this program.

in order to display our analysis, we need at least two sets of data. in order to do this, we will use bash to run the data-collection line of code multiple times. 

=
for i in 0 15 75; do for j in 0 1;do python3 ParameterizedTimeEDH.py 1 3 0 1 0.05 100 100 1.5 5 0.5 16 1000 $i $j 1; done; done
=

now that we have our six datasets, we need to repackage them to fit our needs. just as an example, we're going to check if there's a difference between the results of freerunmode and non-feerunmode.
to do that, we just specify what's different in the filenames. thankfully, the asterisk always gives it's results in the order of ASCII.

NOTE: This assumes you have deleted the RunData from example 1. if you have not, statrun will not work.

=
python3 repackager.py 1 Free.npz RunData/free-True-sig-1.0000-bkg-3.0000*
python3 repackager.py 1 NotFree.npz RunData/free-False-sig-1.0000-bkg-3.0000*
=

now then, we have our full dataset. all we need to do is run our tests. all we need now is to run the command

=
python3 statrun.py 1 0 0.05 Free.npz NotFree.npz
=

following this, the program will print out the results of the T-Test.

-------------------------------------------------------------------------------------------------
Reports:

all write-up information is in the WriteUp folder, in the files Report and Slides, under the names Report.tex and slides.tex

To compile my writeup, one needs a LaTeX distro from  2025 or later, and to install the package Biber with the following command:

sudo apt install texlive-bibtex-extra

To compile my write-up, one needs to input the following five commands:

pdflatex [name].tex

biber [name]

pdflatex [name].tex

pdflatex [name].tex

pdflatex [name].tex


where [name] is either Report or slides depending on what one is attempting to compile

(I am aware four of the five lines are exactly the same. Each compilation is important. Do not skip this step or the bibliography will not load.)

